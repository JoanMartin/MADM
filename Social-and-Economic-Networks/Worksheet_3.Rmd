---
title: "Social and economic networks"
subtitle: "Handout 3"
author: "Juan José Martín y Christian Strasser"
output:
  html_document:
    number_sections: false
    highlight: tango
    toc: yes
    df_print: paged
editor_options: 
  chunk_output_type: console
---



<style type="text/css">

  body {
    background-color: #f6f7fd; 
  }
  
  a:link {
    color: #0174DF;
  }
  
  code.r {
    font-size: 14px;
  } 
  
  div pre {
    background-color:#E0ECF8;
  }
  pre {
    font-size: 14px 
  }
 
  p {
    text-align: justify;
  }
 
    
  h1, h2, h3, h4, h5, h6 {
    color: #737aaa;
  }

  th {  
    background-color:#737aaa;
    color: #FAFAFA;
    padding:5px;
  }
  
  td {
    font-size: 11.5pt;
  } 
  
  tr:nth-child(even){
    background: white;
  }
  
  tr:nth-child(odd){ 
    background-color: #EFF8FB;
  }
</style>

***    

## Ejercicio 1

**For the graph in Fig. 1:**
```{r, results='hide', message=FALSE, warning=FALSE}
library(igraph)
library(ggplot2)
library(reshape2)
library(knitr)
```

```{r, fig.align='center'}
g = graph_from_literal(1---4, 1---5, 1---8, 2---3, 2---4, 2---9, 3---6, 3---4, 4---5,  4---6, 5---8, 5---9, 6---7, 6---8)
plot(g)
```


(1) **Its adjacency matrix**

```{r}
get.adjacency(g, sparse = FALSE)
```

<br>

(2) **Its density**

```{r}
edge_density(g, loops = FALSE)
```

<br>

(3) **The degree of each node**
```{r}
degree(g)
```

<br>

(4) **Its average degree and its degrees standard deviation**

El grado medio es:
```{r}
mean(degree(g))
```

<br>

Y la desviación estándar de los grados es:
```{r}
sd(degree(g))
```

<br>

(5) **Its degrees distribution and cumulative distribution, and plot them**

La distribución de los grados es:
```{r, fig.align='center'}
degree.distribution(g)
```

<br>

y generamos su gráfica:
```{r, fig.align="center"}
plot(0:max(degree(g)), degree_distribution(g),pch=20,main="Degree density",xlab="Degree",
     ylab="Probability",type="o")
```

<br>

La distribución acumulada de los grados es:
```{r}
degree.distribution(g, cumulative = TRUE)
```

<br>

Giramos la distribución acumulada de los grados:
```{r}
TrDD = c(1-degree_distribution(g,cumulative=TRUE)[-1], 1)
round(TrDD, 4)
```

<br>

y generamos su gráfica:
```{r, fig.align="center"}
plot(0:max(degree(g)), TrDD,pch=20,main="Degree cumulative distribution",xlab="Degree",
     ylab="Probability",type="o")
```


<br>

(6) **The distances from 1 to the other nodes**
```{r}
kable(distances(g, 1))
```

<br>

(7) **Its diameter, and a pair of nodes at maximum distance**
```{r}
diameter(g)
farthest_vertices(g)$vertices
```

<br>

El par de nodos que está a máxima distancia es 7 - 9.

<br>

(8) **The clustering coefficient of each node, and a node with maximum clustering coefficient**

El coeficiente de clustering de cada nodo es:

```{r}
coef_clus = c()
for(i in 1:gorder(g)){
  coef_clus = c(coef_clus, transitivity(g, type="local", vids = i))
  if(coef_clus[i]=="NaN"){
    coef_clus[i] = 0
  }
}
coef_clus
```

<br>

Vemos que hay dos nodos que tienen el máximo coeficiente de clustering 0.6666667 que son:
```{r}
which(coef_clus == max(coef_clus))
```

el nodo 1 y 6.

<br>

(9) **Its average clustering coefficient**
```{r}
round(transitivity(g, type="average"), 4)
```

<br>

(10) **Its transitivity coefficient**
```{r}
round(transitivity(g), 4)
```

<br>

(11) **Its average distance**
```{r}
round(mean_distance(g))
```

<br>

(12) **Its relative hop plot**
```{r, fig.align='center'}
rel_hop_plot = function(G) {
  
  F = function(x){
    length(unlist(ego(G, order=x, nodes=V(G)))) / length(V(G)) ^ 2
  }

  sapply(1:diameter(G), FUN=F)
}

plot(rel_hop_plot(g), pch=20, main="Relative hop plot", xlab="Hops", ylab="Probability", type="o")
```

<br>

## Ejercicio 2

**Consider a ring G with 100 nodes, labeled consecutively 1, 2, ..., 100.**

```{r, fig.align='center', fig.width=10}
g_ring = make_ring(100, directed = FALSE)
plot(g_ring, layout = layout.circle)
```


(a) **What are its average distance and its diameter?**

```{r}
round(mean_distance(g_ring))
diameter(g_ring)
```

<br>

(b) **Now, chose equiprobably a new (that is, not existing in G) edge incident to the node 1 and add it to G. What are the expected average distance and the expected diameter of the new graph obtained in this way? You can compute these expected indices analitically (that is, by hand) or estimate them by a Monte Carlo method with 10,000 iterations (that is, generate randomly 10,000 such graphs, compute their indices, and then estimate the expected indices from this sample). Bonus if you do it both ways and the results are consistent.**

Para añadir una arista desde el nodo 1 a cualquier otro nodo de forma equiprobable, sobre el grafo inicial $G$ añadimos una nueva arista y calculamos su distancia media. Esta acción la realimos 97 veces más (una por cada nodo diferente de 2 y 100, ya que estos son nodos vecinos de 1). Finalmente, calculamos la media de las distancias medias, y la media de su diámetro, de haber añadido 98 veces una nueva arista desde el nodo a cualquiera de los demás nodos.

Es importante tener claro que en cada iteración se genera un nueva grafo (a partir del grafo original) con una nueva arista desde el nodo 1 a cualquier otro nodo. Es decir, en ningún caso se genera un único grafo con 97 aristas nuevas.

```{r}
g_ring_original = make_ring(100, directed = FALSE)
Avg_D = c()
Diam = c()
for(i in 3:99){
  g_ring = add_edges(g_ring_original, c(1, i))
  Avg_D = c(Avg_D, mean(distances(g_ring)))
  Diam = c(Diam, diameter(g_ring))
}
```

<br>

```{r}
round(mean(Avg_D))
round(mean(Diam))
```

<br>

Podemos observar que la distancia media con respecto al grafo original $G$ se ha reducido al añadir esa nueva arista.

<br>

Mediante el método Monte Carlo, lo que se hace es generar 10000 valores entre 3 y 99 (nodos diferentes de 2 y 100, ya que estos son nodos vecinos de 1) de forma aleatoria para, finalmente, sacar la media de las distancias medias y la media de su diámetro.

Hay que tener en cuenta que se cogen los nodos de forma aleatoria y no de forma secuencial como se ha hecho en el anterior ejemplo. Esto causará que haya nodos que se repitan en diferentes iteraciones.

```{r}
Avg_D = c()
Diam = c()
for(i in 1:10000){
  v_random = sample(3:99, 1)
  g_ring = add_edges(g_ring_original, c(1, v_random))
  Avg_D[i] = mean_distance(g_ring)
  Diam[i] = diameter(g_ring)
}
```

<br>

```{r}
round(mean(Avg_D))
round(mean(Diam))
```

<br>

Vemos que la media de las distancias y la media de los diámetros da lo mismo que el método realizado anteriormente.

<br>

## Ejercicio 3

**Find a family of graphs $(H_n)_n$ with order $(H_n) = n$ such that $C(H_n){\longrightarrow}0$ and $T(H_n){\longrightarrow}1$.**

El grafo $(H_n)_n$ con orden $(H_n) = n$ sería un grafo completo como, por ejemplo:
```{r, fig.align='center'}
full_g = graph_from_literal(1---2, 1---3, 1---4, 1---5, 2---3, 2---4, 2---5, 3---1, 3---2, 3---4, 3---5, 4---1, 4---2, 4---3, 4---5, 5---1)
plot(full_g)
```

<br>

Este grafo completo tendrá el coeficiente de clustering y de transitividad igual a 1.

```{r}
transitivity(full_g) # Transitivity coefficient
transitivity(full_g, type="average") # Clustering coefficient
```

<br>

Por lo tanto, para que este grafo cumpliera la condición $\lim_{n \to \infty} C(H_n) = 0$, habría que añadir al grafo completo un grafo tal que su número de triángulos fuera igual a 0. Por ejemplo, una cadena:

```{r, fig.align='center'}
chain_g = graph_from_literal(1---2, 2---3, 3---4, 4---5)
plot(chain_g)
```

<br>

cuyo coeficiente de clustering y de transitividad es igual a 0.

```{r}
transitivity(chain_g) # Transitivity coefficient
transitivity(chain_g, type="average") # Clustering coefficient
```

<br>

Además, para que realmente se cumpla $\lim_{n \to \infty} C(H_n) = 0$, la cadena deberá tener más nodos que el grafo completo para que el número de tripletas sea mayor que el número de triángulos. Esto se debe por la fórmula del coeficiente de clustering:

$$ C(H) = \frac{\lambda(v)}{\tau(v)} $$
donde $\lambda(v)$ es el número de triángulos y $\tau(v)$ es el número de tripletas.

Para saber cuántos nodos más ha de tener la cadena con respecto al grafo completo, se ha utilizado el artículo [The difference between the transitivity ratio and the clustering coefficient](http://pages.stat.wisc.edu/~karlrohe/netsci/MeasuringTrianglesInGraphs.pdf) de _Karl Rohe_, donde se demuestra que para un grafo con $n$ nodos, el grafo completo ha de tener $n^{2/3}$ nodos, y la cadena el resto de nodos.

Por lo tanto, el siguiente algoritmo realiza 999 iteraciones donde, por cada iteración $i$, se generará un nuevo grafo $H$ de $n = i$ nodos formado por un grafo completo de $x = n^{2/3}$ nodos y una cadena de $y = n - x$ nodos. Para cada grafo generado, se calcula sus coeficientes de clustering y de transitividad.

```{r}
clus = c()
trans = c()

for (i in 2:1000) {
  x = ceiling(i^(2/3))
  y = i - x
  
  full_g = make_full_graph(x)
  chain_g = graph(sort(cbind(seq(x, x+y-1), seq(x+1, x+y))), directed = FALSE)
  H_g = graph.union(full_g, chain_g)
  
  trans[i] = transitivity(H_g) # Transitivity coefficient
  clus[i] = transitivity(H_g, type="average") # Clustering coefficient
}
```

<br>

Finalmente, generamos una gráfica con los coeficientes de clustering y de transitividad para cada grafo generado.

```{r, fig.align='center', fig.width=10}
df = na.omit(data.frame(x=clus, y=trans))
colnames(df) = c('clus', 'trans')
df['seq'] = seq(1, length(df$clus))
df = melt(df, id.vars='seq')

ggplot(df) + 
  geom_point(aes(x=seq, y=value, color=variable)) + 
  scale_color_discrete(name="Coefficients",
                      breaks=c("clus", "trans"),
                      labels=c("Clustering", "Transitivity")) +
  xlab("n nodes of graph H") +
  ylab("Coefficients of clustering and transitivity")
```

<br>

Se puede observar como se cumple $\lim_{n \to \infty} C(H_n) = 0$ y $\lim_{n \to \infty} T(H_n) = 1$ para un grafo $H$ de $n$ nodos formado por un grafo completo de $n^{2/3}$ nodos y una cadena de $n - n^{2/3}$ nodos.

<br>

