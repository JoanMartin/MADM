{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from itertools import groupby\n",
    "import glob\n",
    "import hashlib\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simhash\n",
    "\n",
    "Simhash es una técnica para estimar rápidamente cuán similares son dos conjuntos. Es usada por <strong>Crawler</strong> de Google para encontrar páginas duplicadas o similares.\n",
    "\n",
    "El algoritmo de Simhash consta de los siguientes 4 pasos:\n",
    "\n",
    "<ol>\n",
    "    <li>\n",
    "        Procesar el documento dejando un conjunto de variables con un peso asociado. En este caso se considerarán estas variable como <i>palabras</i> con su frecuencia como peso.\n",
    "    </li>\n",
    "    <li>\n",
    "        Generar un valor único de hash para cada variable de <i>b</i> bits (el valor deseado de la huella difital (<i>Fingerprint</i>). \n",
    "    </li>\n",
    "    <li>\n",
    "        Crear un <i>b-dimensional</i> vector $V$ en el que se sumará o restará en cada posición el peso de cada variable dependiendo de si el bit de su hash en esa misma posición es 1 o 0, respectivamente.\n",
    "    </li>\n",
    "    <li>\n",
    "        Después de que todas las variables hayan sido procesadas, se genera una huella digital de $b$ bits poniendo los bits a 1 o 0 dependiendo de si el valor en la posición del vector $V$ es positiva o negativa, respectivamente.\n",
    "    </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"Tropical fish include fish found in tropical environments around the world, \\\n",
    "        including both freshwater and salt water species.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1. Procesamiento del documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El procesamiento del documento tendrá como primer paso la tokenización (segmentación) del documento para eliminar la palabras menos usadas (**stop words**) y los signos de puntuación y, en caso de que se desee, poner las palabras en minúscula para, finalmente, generar una lista con las palabras necesarias. Estas acciones son las que he querido realizar para este ejercicio, pero se podrían hacer otras dependiendo del idioma del documento, tipo de análisis que se desee realizar, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tropical', 'fish', 'include', 'fish', 'found', 'tropical', 'environments', 'around', 'world', 'including', 'freshwater', 'salt', 'water', 'species']\n"
     ]
    }
   ],
   "source": [
    "stopWords = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "data_lower = data.lower()\n",
    "words = tokenizer.tokenize(data_lower)\n",
    "words = list(filter(lambda token: token not in stopwords.words('english'), words))\n",
    " \n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segunda parte del procesamiento del documento será asignar un peso a cada palabra que, en este caso, es su frecuencia de aparación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'around': 1,\n",
       " 'environments': 1,\n",
       " 'fish': 2,\n",
       " 'found': 1,\n",
       " 'freshwater': 1,\n",
       " 'include': 1,\n",
       " 'including': 1,\n",
       " 'salt': 1,\n",
       " 'species': 1,\n",
       " 'tropical': 2,\n",
       " 'water': 1,\n",
       " 'world': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_dict = {k:sum(1 for _ in g) for k, g in groupby(sorted(words))}\n",
    "words_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2 y 3. Generación de los valores hash y creación del vector $V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de hash empleada en este caso es **MD5**, la cual genera una secuencia de 128 bits. Para poder coger los últimos $b$ bits de cada secuencia, se ha utilizado **& ((1 << b) - 1)**, lo que crea una máscara de $b$ bits igual a 1.\n",
    "\n",
    "Posteriormente, se genera el hash por cada palabra y se suma o resta en la posición correspondiente de vector $V$ el peso de la palabra dependiendo de si el bit de su hash en esa misma posición es 1 o 0, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores de hash:\n",
      "\n",
      "environments  -  0b101111\n",
      "salt  -  0b11101110\n",
      "species  -  0b10110010\n",
      "world  -  0b11100111\n",
      "fish  -  0b1001\n",
      "include  -  0b10000001\n",
      "around  -  0b10010101\n",
      "freshwater  -  0b11000011\n",
      "tropical  -  0b11110101\n",
      "found  -  0b1111010\n",
      "including  -  0b11000110\n",
      "water  -  0b101100\n",
      "\n",
      "\n",
      "Vector V: [4, 0, 2, -4, -2, 2, 0, 4]\n"
     ]
    }
   ],
   "source": [
    "def hashfunc(x, b=128):\n",
    "    hexad = int(hashlib.md5(x).hexdigest(), 16)\n",
    "    return hexad & ((1 << b) - 1)\n",
    "\n",
    "b = 8\n",
    "\n",
    "print('Valores de hash:\\n')\n",
    "\n",
    "v = [0] * b\n",
    "for word in words_dict.items():\n",
    "    h = hashfunc(word[0].encode('utf-8'), b)\n",
    "    w = word[1]\n",
    "    \n",
    "    print(word[0], ' - ', bin(h))\n",
    "    \n",
    "    for i in range(b):\n",
    "        v[b - 1 - i] += w if h >> i & 1 else -w\n",
    "\n",
    "print('\\n\\nVector V:', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4. Generación de la huella digital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se genera la huella digital (*Fingerprint*) de $b$ bits poniendo los bits a 1 o 0 dependiendo de si el valor en la posición del vector $V$ es positiva o negativa, respectivamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint: 165\n",
      "Fingerprint en bits: 0b10100101\n"
     ]
    }
   ],
   "source": [
    "fingerprint = 0\n",
    "for i in range(b):\n",
    "    if v[b - 1 - i] > 0:\n",
    "        fingerprint |= (1 << i)\n",
    "\n",
    "print('Fingerprint:', fingerprint)\n",
    "print('Fingerprint en bits:', bin(fingerprint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función de tokenización en la que se da al usuario la elección de poner todas las palabras de un documento en minúscula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, lower=True, lang='english'):\n",
    "    stopWords = set(stopwords.words(lang))\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    \n",
    "    if lower:\n",
    "        text = text.lower()\n",
    "    words = tokenizer.tokenize(text)\n",
    "    words = list(filter(lambda token: token not in stopwords.words('english'), words))\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función hash explicada anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashfunc(x, b=128):\n",
    "    hexad = int(hashlib.md5(x).hexdigest(), 16)\n",
    "    return hexad & ((1 << b) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo de **Simhash** en el que se pasa por parámentro un documento tokenizado y, opcionalmente, un valor para $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simhash(tokenized_doc, b=128):    \n",
    "    words_dict = {k:sum(1 for _ in g) for k, g in groupby(sorted(tokenized_doc))}\n",
    "\n",
    "    v = [0] * b\n",
    "    for word in words_dict.items():\n",
    "        h = hashfunc(word[0].encode('utf-8'), b)\n",
    "        w = word[1]\n",
    "\n",
    "        for i in range(b):\n",
    "            v[b - 1 - i] += w if h >> i & 1 else -w\n",
    "            \n",
    "    fingerprint = 0\n",
    "    for i in range(b):\n",
    "        if v[b - 1 - i] > 0:\n",
    "            fingerprint |= (1 << i)\n",
    "    \n",
    "    return fingerprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función con la que se puede calcular la distancia (número de bits diferentes) entre dos huellas digitales. El símbolo **^** es el operador *OR exclusivo bit a bit*, en el que entre dos secuencias de bits si un bit es 0 y el otro bit es 1, el bit del resultado correspondiente se establece en 1. De lo contrario, el bit del resultado correspondiente se establece en 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(fingerprint1, fingerprint2, b=128):\n",
    "    x = (fingerprint1 ^ fingerprint2) & ((1 << b) - 1)\n",
    "    dist = 0\n",
    "    while x:\n",
    "        dist += 1\n",
    "        x &= x - 1\n",
    "        \n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, muestro un ejemplo de Simhash de 8 bits de dos documentos iguales, donde la única diferencia es que en el tokenizado del segundo se ha especificado que no se convierta a minúscula ninguna palabra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingerprint del primer documento 165\n",
      "Fingerprint del primer documento 167\n",
      "Bits diferentes entre ambos documentos: 1 de 8\n"
     ]
    }
   ],
   "source": [
    "doc1 = \"Tropical fish include fish found in tropical environments around the world, \\\n",
    "        including both freshwater and salt water species.\"\n",
    "\n",
    "doc2 = \"Tropical fish include fish found in tropical environments around the world, \\\n",
    "        including both freshwater and salt water species.\"\n",
    "\n",
    "b = 8\n",
    "\n",
    "# Simhash of doc1\n",
    "tokenized_doc1 = tokenize(doc1)\n",
    "fingerprint1 = simhash(tokenized_doc1, b)\n",
    "\n",
    "# Simhash of doc2\n",
    "tokenized_doc2 = tokenize(doc2, lower=False)\n",
    "fingerprint2 = simhash(tokenized_doc2, b)\n",
    "\n",
    "# Distance between doc1 and doc2\n",
    "dist = distance(fingerprint1, fingerprint2, b)\n",
    "\n",
    "print('Fingerprint del primer documento', fingerprint1)\n",
    "print('Fingerprint del primer documento', fingerprint2)\n",
    "print('Bits diferentes entre ambos documentos:', dist, 'de', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo con libros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se van a comparar los siguientes libros en inglés:\n",
    "\n",
    "<ol>\n",
    "    <li>Alicia en el País de las Maravillas</li>\n",
    "    <li>Drácula</li>\n",
    "    <li>La primera mitad del mismo libro de Drácula. Lo he llamado **dracula_break**</li>\n",
    "    <li>Frankestein</li>\n",
    "    <li>Moby Dick</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar la siguiente función para generar una matriz de las distancias entre cada uno de los libros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distances_matrix(simhashes):\n",
    "    iterables = [simhashes, simhashes]\n",
    "    simhashes_comb = {key : [] for key in simhashes}\n",
    "\n",
    "    for t in itertools.product(*iterables):\n",
    "        dist = distance(simhashes[t[0]], simhashes[t[1]], b)\n",
    "        simhashes_comb[t[0]].append(dist)\n",
    "\n",
    "    df_matrix = pd.DataFrame.from_items(simhashes_comb.items(), \n",
    "                                        orient='index', \n",
    "                                        columns=list(simhashes_comb.keys()))\n",
    "    return df_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con 8 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alice_adventures.txt': 92,\n",
       " 'dracula.txt': 90,\n",
       " 'dracula_break.txt': 90,\n",
       " 'frankestein.txt': 122,\n",
       " 'moby_dick.txt': 74}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 8\n",
    "simhashes_8 = {}\n",
    "\n",
    "for files in glob.glob(\"*.txt\"):\n",
    "    infile = open(files, mode='r')\n",
    "    filename = infile.name\n",
    "    a = infile.read()\n",
    "    infile.close()\n",
    "    \n",
    "    token = tokenize(a)\n",
    "    simh = simhash(token, b)\n",
    "    simhashes_8[filename] = simh\n",
    "        \n",
    "simhashes_8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frankestein.txt</th>\n",
       "      <th>dracula_break.txt</th>\n",
       "      <th>moby_dick.txt</th>\n",
       "      <th>dracula.txt</th>\n",
       "      <th>alice_adventures.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frankestein.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dracula_break.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moby_dick.txt</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dracula.txt</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alice_adventures.txt</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      frankestein.txt  dracula_break.txt  moby_dick.txt  \\\n",
       "frankestein.txt                     0                  2              1   \n",
       "dracula_break.txt                   1                  1              0   \n",
       "moby_dick.txt                       2                  0              1   \n",
       "dracula.txt                         1                  1              0   \n",
       "alice_adventures.txt                3                  3              2   \n",
       "\n",
       "                      dracula.txt  alice_adventures.txt  \n",
       "frankestein.txt                 1                     3  \n",
       "dracula_break.txt               0                     2  \n",
       "moby_dick.txt                   1                     3  \n",
       "dracula.txt                     0                     2  \n",
       "alice_adventures.txt            2                     0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_matrix(simhashes_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con 64 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alice_adventures.txt': 9984005856265639004,\n",
       " 'dracula.txt': 10956864711739610202,\n",
       " 'dracula_break.txt': 11100979968513971290,\n",
       " 'frankestein.txt': 12271427276163265658,\n",
       " 'moby_dick.txt': 724754358419373130}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 64\n",
    "simhashes_64 = {}\n",
    "\n",
    "for files in glob.glob(\"*.txt\"):\n",
    "    infile = open(files, mode='r')\n",
    "    filename = infile.name\n",
    "    a = infile.read()\n",
    "    infile.close()\n",
    "    \n",
    "    token = tokenize(a)\n",
    "    simh = simhash(token, b)\n",
    "    simhashes_64[filename] = simh\n",
    "        \n",
    "simhashes_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frankestein.txt</th>\n",
       "      <th>dracula_break.txt</th>\n",
       "      <th>moby_dick.txt</th>\n",
       "      <th>dracula.txt</th>\n",
       "      <th>alice_adventures.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frankestein.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dracula_break.txt</th>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moby_dick.txt</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dracula.txt</th>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alice_adventures.txt</th>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      frankestein.txt  dracula_break.txt  moby_dick.txt  \\\n",
       "frankestein.txt                     0                 16             13   \n",
       "dracula_break.txt                  13                 11              0   \n",
       "moby_dick.txt                      16                  0             11   \n",
       "dracula.txt                        15                 13              4   \n",
       "alice_adventures.txt               22                 16             15   \n",
       "\n",
       "                      dracula.txt  alice_adventures.txt  \n",
       "frankestein.txt                15                    22  \n",
       "dracula_break.txt               4                    15  \n",
       "moby_dick.txt                  13                    16  \n",
       "dracula.txt                     0                    17  \n",
       "alice_adventures.txt           17                     0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_matrix(simhashes_64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con 128 bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alice_adventures.txt': 327763483949349671204758320733936030812,\n",
       " 'dracula.txt': 336108638123220734845428257125189063770,\n",
       " 'dracula_break.txt': 336119022716937653385101981545975026778,\n",
       " 'frankestein.txt': 316086574081351765772503192164555043962,\n",
       " 'moby_dick.txt': 250884428747321189650351009777993169994}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = 128\n",
    "simhashes_128 = {}\n",
    "\n",
    "for files in glob.glob(\"*.txt\"):\n",
    "    infile = open(files, mode='r')\n",
    "    filename = infile.name\n",
    "    a = infile.read()\n",
    "    infile.close()\n",
    "    \n",
    "    token = tokenize(a)\n",
    "    simh = simhash(token, b)\n",
    "    simhashes_128[filename] = simh\n",
    "        \n",
    "simhashes_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frankestein.txt</th>\n",
       "      <th>dracula_break.txt</th>\n",
       "      <th>moby_dick.txt</th>\n",
       "      <th>dracula.txt</th>\n",
       "      <th>alice_adventures.txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>frankestein.txt</th>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dracula_break.txt</th>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moby_dick.txt</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dracula.txt</th>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alice_adventures.txt</th>\n",
       "      <td>47</td>\n",
       "      <td>42</td>\n",
       "      <td>34</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      frankestein.txt  dracula_break.txt  moby_dick.txt  \\\n",
       "frankestein.txt                     0                 39             27   \n",
       "dracula_break.txt                  27                 28              0   \n",
       "moby_dick.txt                      39                  0             28   \n",
       "dracula.txt                        29                 32              6   \n",
       "alice_adventures.txt               47                 42             34   \n",
       "\n",
       "                      dracula.txt  alice_adventures.txt  \n",
       "frankestein.txt                29                    47  \n",
       "dracula_break.txt               6                    34  \n",
       "moby_dick.txt                  32                    42  \n",
       "dracula.txt                     0                    36  \n",
       "alice_adventures.txt           36                     0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_matrix(simhashes_128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados finales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuanto mayor es el tamaño de $b$, más se pueden apreciar las diferencias entre los libros a través de su distancia. Por ejemplo, entre el libro de Drácula entero y el de solo la primera mitad, con 8 bits nos muestra que no hay diferencias, mientras que con 64 y 128 ya podemos ver como sí que hay una pequeña diferencia. De todas maneras, con las 3 formas sabríamos que son documentos con un alto índice de duplicidad.\n",
    "\n",
    "Otro ejemplo es el de Moby Dick. Con 8 y 64 bits es difícil ver con cuál tiene más diferencias. No obstante, con 128 bits se ve claramente como tiene una mayor diferencia con Alicia en el País de las Maravillas y Frankestein."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
