---
title: "Còdigo del Trabajo Final"
subtitle: '**Aprendizaje supervisado y toma de decisiones**'
author: Maria del Mar Bibiloni Femenias
output:
  html_document:
    number_sections: false
    toc: true
    theme: default
    highlight: tango
    df_print: paged
editor_options: 
  chunk_output_type: console
---


<style type="text/css">
  
  a:link {
    color: #0174DF;
  }
  
  code.r {
    font-size: 14px;
  } 
  
  div pre {
    background-color:#E0ECF8;
  }
  pre {
    font-size: 14px 
  }
 
  p {
    text-align: justify;
  }
 
  h1, h2, h3, h4, h5, h6 {
    color: #088A85;
  }

  th {  
    background-color:#088A85;
    color: #FAFAFA;
    padding:5px;
  }
  
  td {
    font-size: 11.5pt;
  } 
  
  tr:nth-child(even){
    background: white;
  }
  
  tr:nth-child(odd){ 
    background-color: #EFF8FB;
  }
</style>

<br>

***


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

En este documento se prentende mostrar todo el código utilizado para realizar el trabajo final de la asignatura _Aprendizaje estadístico y toma de deciciones_.

_No terminado; sólo aparecen algunas notas._

##Sobre los datos originales

Los datos de mamografías a mujeres con tumores benignos y malignos se pueden descargar del repositiorio UCI, [aquí](http://archive.ics.uci.edu/ml/datasets/Mammographic+Mass).


Cargamos los datos.
```{r}
original_data= read.table("mammographic_masses.data.txt", sep=",", header=FALSE) 
```

Nombramos las columnas.

```{r}
colnames(original_data) <- c("BIRADS", "Age", "Shape", "Margin", "Density", "Severity")
```


Vemos las primeras filas.
```{r}
head(original_data,10)
```

Dimensiones.
```{r}
matrix(dim(original_data),nrow=2, ncol=1, dimnames=list(c("Observations: ","Predictors:"), ""))
```

Benign-Malign
```{r}
apply(original_data[,-2], 2, function(x) table(x))
```

En BI-RADS un valor se nos sale del rango: 55.
Podemos suponer que es 5 o quitar la observación. La quitamos.

```{r}
data<-original_data
data=data[-which(original_data$BIRADS==55),]
apply(data[,-2], 2, function(x) table(x))
```


###NaN

Veamos cuantos NaN tenemos por columna.
```{r}
data[data=="?"]<- NaN
apply(data, 2, function(x) sum(is.na(x)))
```

Salvo la edad, no es conveniente cambiar los NaN por algun otro valor.
(edad solo 2 NaN)
Así, nos quedamos sólo con las observaciones completas.

```{r}
data <- data[complete.cases(data),]
dim(data)
```

Tipo numerico.
```{r}
data <- as.data.frame(apply(data, 2, as.numeric))
```


###Train-Test

Tomamos 2/3 de los datos aleatoriamente y los guardamos como train.
La idea es no usar este conjunto para entrenar ningún modelo y así evitar el overfitting.

```{r}
set.seed(1123)
train=sample(nrow(data), size = ceiling(2/3*nrow(data)) )
test=c(1:nrow(data))[-train]
```

En los daos originales hay una buena proporción de casos de tumor benigno y maligno, es decir, no es un problema no balanceado. No hay que modificar la muestra.

Hay que comprobar si se mantiene, aproximadamente, la proporción en _test_ y _train_.

```{r}
matrix(c( table(original_data$Severity)/nrow(original_data),
table(data[train,]$Severity)/length(train),
table(data[test,]$Severity)/length(test) ), nrow=3, ncol=2, byrow = TRUE,
dimnames=list(c("Original set ","Train set", "Test set"), c("Benign (0)","Malign(1)")) )
```

Se mantiene. Ya tenemos los conjuntos de entrenamiento y validación.

###Pair Plot

```{r}
cols <- character(length = length(train))
cols[] <- "black"
cols[data[train,]$Severity == 1] <- "blue"
cols[data[train,]$Severity == 0] <- "orange"
pairs(data[train,], pch = 21, bg = cols )
```


###Variables Dummy

Tenemos varias variabes cuantitativas (ordinales y nominales), por tanto, para usar varios métodos de regresión necesitaremos crear variables dummies.


Crear dummies:
```{r}
library("dummies")
data_dum <-dummy.data.frame(data, names=c("BIRADS","Shape", "Margin", "Density"), sep="_")
head(data_dum)
```

Quitamos las columnas que seran la categoria referencia.

* BI_RADS: 0, incompleto.
* Shape: 4, más común.
* MArgin: 1, más común.
* Density: 3, bajo. (Además, el más común)

```{r}
refCategory=names(data_dum) %in% c("BIRADS_0", "Shape_4", "Margin_1", "Density_3")
data_dum = data_dum[, !refCategory]
head(data_dum)
```

## Mètodos de clasificación

Primero, veamos unos mètodos simples, ya que pueden ir mejor que otros más sofisticados.

### K-nearest neighbors


Elegir la mejor k con validación cruzada 10-veces.
(Aquí no usamos las dummies)

```{r}
library(ISLR)
library(caret)

set.seed(5813)
cross_val <- trainControl(method="cv", number=10)

data$Severity <- as.factor(data$Severity)
knn_fit <- train(Severity ~ ., data = data[train,], method = "knn", metric="Accuracy",  trControl = cross_val, tuneLength = 10)
knn_fit
```

Selecciona 15, pero por la poca diferencia nos podriamos quedar con 9, ya que con menos vecinos evitamos no detectar "zonas" con pocos datos. Comparemos 9 con 15 en test.

* knn con k=5 para saber el error en test.

```{r}
library(class)
library('gmodels')
knn_k5_fit=knn(data[train,], data[test,], cl=data[train,]$Severity, k = 5)
ct_knn=CrossTable(x=data[test,]$Severity, y=knn_k5_fit)
```

Si nos fijamos en los tumores clasificados correctamente, el error es pequeño para tipo.
En otras palabras, no se equivoca mucho en uno de los casos.

```{r}
error_knn5 = (ct_knn$t[2] + ct_knn$t[3])/length(test)
accuracy_knn5=1-error_knn5

accuracy_bening_knn5=(ct_knn$t[1])/(ct_knn$t[1] + ct_knn$t[3])
accuracy_malign_knn5=(ct_knn$t[4])/(ct_knn$t[2] + ct_knn$t[4])
```

```{r}
list_knn5=c(error_knn5, accuracy_knn5, accuracy_bening_knn5,accuracy_malign_knn5)

matrix(list_knn5, nrow=1, ncol=4,
dimnames=list(c("Knn (K=5)"),c("Error", "Accuracy", "Accuracy_bening", "Accuracy_malign")) )
```

* knn con k=15 para saber el error en test.

```{r}
knn_k15_fit=knn(data[train,], data[test,], cl=data[train,]$Severity, k = 15)
ct_knn15=CrossTable(x=data[test,]$Severity, y=knn_k15_fit)
error_knn15 = (ct_knn15$t[2] + ct_knn15$t[3])/length(test)
accuracy_knn15=1-error_knn15

accuracy_bening_knn15=(ct_knn15$t[1])/(ct_knn15$t[1] + ct_knn15$t[3])
accuracy_malign_knn15=(ct_knn15$t[4])/(ct_knn15$t[2] + ct_knn15$t[4])

list_knn15=c(error_knn15, accuracy_knn15, accuracy_bening_knn15,accuracy_malign_knn15)

matrix(c(list_knn5,list_knn15), nrow=2, ncol=4, byrow = TRUE,
dimnames=list(c("Knn (K=5)","Knn (K=15)"),c("Error", "Accuracy", "Accuracy_bening", "Accuracy_malign")) )
```

Nos quedamos con k=5!

### Logistic regression

Estimaremos el modelo con todas las variables dummies.

```{r}
logReg <- glm(Severity ~.,family=binomial(link='logit'),data=data_dum[train,])
logReg$coefficients
```


Error en test.
```{r}
logReg_fit <- predict(logReg,newdata=data_dum[test,-17], type='response')

#>0.5 --> 1; <0.5 --> 0
logReg_fit  <- ifelse(logReg_fit  >= 0.5,1,0)

error_logReg_0 <- mean(logReg_fit   != data_dum[test,]$Severity)
accuracy_logReg_0=1-error_logReg_0

```

```{r}
ct_logReg_0=CrossTable(x=data[test,]$Severity, y=logReg_fit)

accuracy_bening_logReg_0=(ct_logReg_0$t[1])/(ct_logReg_0$t[1] + ct_logReg_0$t[3])
accuracy_malign_logReg_0= (ct_logReg_0$t[4])/(ct_logReg_0$t[2] + ct_logReg_0$t[4])

list_logReg_0=c(error_logReg_0, accuracy_logReg_0, accuracy_bening_logReg_0,accuracy_malign_logReg_0)

matrix(list_logReg_0, nrow=1, ncol=4,
dimnames=list(c("Tree"),c("Error", "Accuracy", "Accuracy_bening", "Accuracy_malign")) )
```


Contrastes de significación, $alpha=0.05$.
```{r}
summary(logReg)
```

Ningún coeficiente del grupo BI-RADS ni Density es significativo.
Matriz de correlaciones.

```{r}
# Melt the correlation matrix

cormat = cor(data[,-6])
get_upper_tri <- function(cormat){
  cormat[lower.tri(cormat)]<- NA
  return(cormat)
}
library(reshape2)
upper_tri <-get_upper_tri(cormat)
melted_cormat <- melt(upper_tri, na.rm = TRUE)
# Heatmap
library(ggplot2)
ggplot(data = melted_cormat, aes(Var2, Var1, fill = value))+
 geom_tile(color = "white")+
 scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
   midpoint = 0, limit = c(-1,1), space = "Lab", 
   name="Pearson\nCorrelation") +
  theme_minimal()+ 
 theme(axis.text.x = element_text(angle = 45, vjust = 1, 
    size = 12, hjust = 1))+
 coord_fixed()
```

Density no està muy correlacionada con ninguna otra variable.
Eliminamos BI-RADS y repetimos ($alpha=0.05$).

```{r}
data_logReg = data_dum[,6:17]
logReg_notBR <- glm(Severity ~.,family=binomial(link='logit'),data=data_logReg[train,])
summary(logReg_notBR)
```

Ahora si, todos los grupos tienen un coeficiente significativo al 5%.

Coeficientes.
```{r}
logReg_notBR$coefficients
```

Error en test.
```{r}
logReg_notBR_fit <- predict(logReg_notBR,newdata=data_logReg[test,-12], type='response')

#>0.5 --> 1; <0.5 --> 0
logReg_notBR_fit  <- ifelse(logReg_notBR_fit  >= 0.5,1,0)

error_logReg <- mean(logReg_notBR_fit  != data_logReg[test,]$Severity)
accuracy_logReg = 1-error_logReg
cat('Error',error_logReg)
cat('Accuracy',accuracy_logReg)
```

Veamos el error por classes.

```{r}
ct_logReg=CrossTable(x=data_logReg[test,]$Severity, y=logReg_notBR_fit)
```

Error quitando coeficientes

```{r}
accuracy_bening_logReg=(ct_logReg$t[1])/(ct_logReg$t[1] + ct_logReg$t[3])
accuracy_malign_logReg= (ct_logReg$t[4])/(ct_logReg$t[2] + ct_logReg$t[4])

list_logReg=c(error_logReg, accuracy_logReg, accuracy_bening_logReg,accuracy_malign_logReg)

matrix(list_logReg, nrow=1, ncol=4,
dimnames=list(c("Tree"),c("Error", "Accuracy", "Accuracy_bening", "Accuracy_malign")) )
```

Comparación logReg

```{r}
matrix(c(list_logReg_0, list_logReg), nrow=2, ncol=4, byrow=TRUE,
dimnames=list(c("Logistic Reg. (All)", "Log Reg. (Not BR)"), c("Error", "Accuracy", "Accuracy_bening", "Accuracy_malign")) )
```


Por ahora nos quedamos con knn. 
No solo buscamos un modelo que reduzca el error de test, sinó uno que reduzca el número de pacientes que se realizan una biopsia innecesária (falsos negativos).
Por otra parte, recordemos que tratamos datos de cancer y, por tanto, no queremos casos de cancer no seleccionados (falsos positivos).

### Árboles de clasificación

Para los árboles de clasificación no es necesario usar las variables dummies.

```{r}
require(ISLR)
require(tree)

#names(data) <- c("BIRADS",  "Age",      "Shape",    "Margin",   "Density",  "Severity")
tree=tree(Severity ~. ,data=data[train,])
plot(tree)
text(tree,pretty=0)
```


Con un árbol de tan poca profundidad, casi no parece necesário hacer validación cruzada para elegir cuando cortar. Aún así, puede haber overfiting al hacer el último paso.

Cabe destacar, que un árbol ayuda a la interpretación. Además en este caso es coherente con la intuición: Si BIRADS es 5, hay una alta sospecha de que sea maligno, por tanto, la biopsia es necesária. En otro caso, hay que analizar los demás resultados para ver si lo és o no, y así evitar un alto número de biopsias innecesarias.

Notemos que no usa Margin ni Density; se basa simplemente en la edad de la mujer y forma del tumor.

Validación cruzada para elegir la profundidad.
```{r}
set.seed(777)
tree_cv=cv.tree(tree,FUN=prune.misclass, K=10)
tree_cv
plot(tree_cv)
```

Nos quedamos con 3 de profundidad


```{r}
prune_tree=prune.misclass(tree,best=3)
plot(prune_tree)
text(prune_tree,pretty=0)
```

Error.

```{r}
tree_fit=predict(prune_tree,data[test,],type="class")
ct_tree=with(data[test,],table(tree_fit,Severity))
ct_tree
```

```{r}
error_tree=(ct_tree[1,2]+ct_tree[2,1])/length(test)
accuracy_tree=1-error_tree

accuracy_bening_tree=(ct_tree[1,1])/(ct_tree[1,1] + ct_tree[2,1])
accuracy_malign_tree=(ct_tree[2,2])/(ct_tree[1,2] + ct_tree[2,2])

list_tree=c(error_tree, accuracy_tree, accuracy_bening_tree,accuracy_malign_tree)

matrix(list_tree, nrow=1, ncol=4,
dimnames=list(c("Tree"),c("Error", "Accuracy", "Accuracy_bening", "Accuracy_malign")) )

```

###Random Forests

##Comparación

```{r}
matrix(c(list_knn5, list_logReg_0, list_logReg, list_tree), nrow=4, ncol=4, byrow=TRUE,
dimnames=list(c("knn (K=5)","Logistic Reg. (All)", "Log Reg. (Not BR)", "Tree (d=3)"), c("Error", "Accuracy", "Accuracy_bening", "Accuracy_malign")) )
```


<br>
