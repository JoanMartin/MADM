---
title: "Hoja de Ejercicios 2 - Parte 2"
subtitle: '**Aprendizaje Estadístico y Toma de Decisiones.**'
author: "Juan José Martín, Marina Moreno, Christian Strasser, Maria del Mar Bibiloni."
output:
  html_document:
    number_sections: false
    highlight: tango
    toc: yes
    df_print: paged
editor_options: 
  chunk_output_type: console
---



<style type="text/css">

  body {
    background-color: #f6f7fd; 
  }
  
  a:link {
    color: #0174DF;
  }
  
  code.r {
    font-size: 14px;
  } 
  
  div pre {
    background-color:#E0ECF8;
  }
  pre {
    font-size: 14px 
  }
 
  p {
    text-align: justify;
  }
 
    
  h1, h2, h3, h4, h5, h6 {
    color: #737aaa;
  }

  th {  
    background-color:#737aaa;
    color: #FAFAFA;
    padding:5px;
  }
  
  td {
    font-size: 11.5pt;
  } 
  
  tr:nth-child(even){
    background: white;
  }
  
  tr:nth-child(odd){ 
    background-color: #EFF8FB;
  }
</style>

***       


```{r, echo=FALSE, include=FALSE}
#setwd("")
```

## Ejercicio 9

**Cargue las libraries _ISLR_ y _boot._ Cargue la base de datos _Boston._ Haz una regresión polinomial para predecir la concentración de óxidos de nitrógeno en partes por 10 millones (_nox_) utilizando sólo la media ponderada de las distancias a cinco centros de empleo de Boston (_dis_). Utilice la validación cruzada de 5, 10 y _n_ Veces (_LOOCV_) para encontrar el orden óptimo para el polinomio (considere $d \in [1; 10]$). Haz el gráfico del error de validación cruzada para cada orden del polinomio, para cada una de las 3 validaciones cruzadas. Proporcione el código y los resultados.**

```{r}
library(ISLR)
library(boot)
library(MASS)
attach(Boston)
```


```{r}
head(Boston)
```

* crim: per capita crime rate by town.
* zn: proportion of residential land zoned for lots over 25,000 sq.ft.
* indus: proportion of non-retail business acres per town.
* chas: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).
* nox: nitrogen oxides concentration (parts per 10 million).
* rm: average number of rooms per dwelling.
* age: proportion of owner-occupied units built prior to 1940.
* dis: weighted mean of distances to five Boston employment centres.
* rad: index of accessibility to radial highways.
* tax: full-value property-tax rate per $10,000.
* ptratio: pupil-teacher ratio by town.
* black: 1000(Bk−0.63)21000(Bk−0.63)2 where Bk is the proportion of blacks by town.
* lstat: lower status of the population (percent).
* medv: median value of owner-occupied homes in $1000s.


```{r}
boston = Boston[c('dis', 'nox')]
head(boston)
dim(boston)
summary(boston)
colSums(is.na(boston))

plot(nox~dis, data=boston)
corr(boston)
```




```{r}
cross_val = function(x, y, k=NA, degree=1:5) {
  
  loocv = function(fit) {
    h = lm.influence(fit)$h
    mean((residuals(fit) / (1-h))^2)
  }
  
  cv_error = NA
  data = data.frame(x1=x, y1=y)
  
  for(d in degree){
    glm_fit = glm(x1~poly(y1, d), data=data)
    
    if (is.na(k)) {
      cv_error[d] = loocv(glm_fit)
    } else {
      cv_error[d] = cv.glm(data, glm_fit, K=k)$delta[1]
    }
  }
  
  return (cv_error)
}
```



```{r}
degree=1:10

cv_error_5 = cross_val(x=nox, y=dis, k=5, degree=degree)
cv_error_10 = cross_val(x=nox, y=dis, k=10, degree=degree)
cv_error_n = cross_val(x=nox, y=dis, degree=degree)
```



```{r}
plot_cv_error = function(cv_error) {
  plot(degree, cv_error, xlab="Orden", ylab="Error de Validación Cruzada 5-Veces", type="b", pch=20, lwd=2,  ylim=c(0.0020, 0.02))
  min.point = min(cv_error)
  sd.points = sd(cv_error)
  abline(h=min.point + 0.2 * sd.points, col="red", lty="dashed")
  abline(h=min.point - 0.2 * sd.points, col="red", lty="dashed")
  legend("topright", "Lineas de 0.2 desviaciones típicas", lty="dashed", col="red")
}
```


```{r, fig.align="center"}
plot_cv_error(cv_error_5)
```



```{r, fig.align="center"}
plot_cv_error(cv_error_10)
```


```{r, fig.align="center"}
plot_cv_error(cv_error_n)
```


#Ejercicio 10

**Cargue la package "Lock5Data" y los datos "CommuteAtlanta".**

<ul>

```{r warning=FALSE, message=FALSE}
library(Lock5Data)
datos=CommuteAtlanta
head(datos)
```

</ul> 
<br> 

(a) **De una estimación de la media poblacional de "Distance". Llámela de $\tilde{\mu}$.**

<ul>
Para dar una estimación de la media poblacional de Distance, lo que haremos serà la media de los valores de esta variable:


```{r}
mu_tilde=mean(datos$Distance)
mu_tilde
```

</ul> 
<br> 

(b) **De una estimación del error estándar de $\tilde{\mu}$. Interprete este resultado.**

<ul>

Para dar una estimación del error estándar de $\tilde{\mu}$, lo que haremos será calcular la desviación típica de los valores de esta variable distancia y los dividiremos por la raíz del numero de observaciones, es decir:

$$SE_\tilde{\mu}\ = \frac{s}{\sqrt{n}} $$


```{r}
s=sd(datos$Distance)
n=dim(datos)[1]
s/sqrt(n)

```

Podemos observar que el error estándar es relativamente pequeño, en consecuencia los valores de la media muestral no oscilan demasiado alrededor del verdadero valor de la media poblacional.

</ul> 
<br> 

(c) **Ahora estime el error estándar de  $\tilde{\mu}$ usando el Bootstrap con $B = 100 000$ muestras de boostrap. Compare los resultados con los del apartado (b).**

<ul>

Construimos la función que nos calculará el error estandar de la media para el método Bootstrap:

```{r}
library(boot)

err.est.media=function(x){
  sd(x)/sqrt(length(x))
}

err.est.media.fn=function(data, index){
  with(data[index,],err.est.media(Distance)) 
}

boot.out=boot(datos,err.est.media.fn,R=100000)
boot.out

```


 Podemos observar que hemos obtenido la misma estimación del error estándar de $\tilde{\mu}$, como era de esperar (`r boot.out$t0`) . Por otro lado, el bias (`r -boot.out$t0+mean(boot.out$t)`), es decir, la difencia valor entre el estimado y la media de las nuevas muestras, es pequeño y esto es bueno porque cuando más pequeño es,  más pequeño será la desviación estándar. Finalmente, podemos ver que hemos obtenido que una desviación estándar muy pequeña (`r sd(boot.out$t) `), por lo que podemos decir que la estimación del error estándar para la media de la variable Distance es fiable.
 </ul> 

 
<br> 

(d) **A partir de la estimación de Bootstrap del apartado (c), calcule un Intervalo de Confianza del 95% para la media poblacional de "Distance". Utilice el método del percentil. Compare los resultados con el intervalo de confianza obtenido utilizando la distribución Normal.**

<ul>
Para calcular el intervalo de confianza con el método del percentil cogeremos las 100000 estimaciones que se han considerado en la función boot del apartado anterior, las ordenaremos y nos quedaremos con el 95% central de las estimaciones:



```{r}
estimaciones=sort(boot.out$t,decreasing = FALSE)
lim_inf=round((length(estimaciones)+1)*(5/(2*100)))
lim_sup=round((length(estimaciones)+1)*(1-5/(2*100)))
intervalo=range(estimaciones[lim_inf:lim_sup])
intervalo
```

En consecuencia el intervalo obtenido es (`r intervalo[1]`,`r intervalo[2]`). Esto implica que en un 95% de los casos el verdadero valor de la media de la población se encontrará en este intervalo.




Por otro lado calculemos intervalo obtenido utilizando la distribución normal. Como estamos cogiendo una muestra de estimaciones muy grande (100000) por el teorema central del límite  $\tilde{\mu}$ se distribuye normalmente, en consecuencia podemos calcular un intervalo de confianza para la media poblacional de la siguiente forma:

$$\left( (T-\tilde{B}^*) - z_{1-\alpha/2}\tilde{SE}^*(T^*), (T-\tilde{B}^*) + z_{1-\alpha/2}\tilde{SE}^*(T^*) \right) $$

Como queremos un intervalo del 95%, entonces $\alpha=0.05$:


```{r}
T=boot.out$t0
Bias =-boot.out$t0+mean(boot.out$t)
z=qnorm(1-0.05/2)
SE=sd(boot.out$t)
liminf= (T-Bias)-z*SE
limsup=(T-Bias)+z*SE
T
Bias
z
SE
liminf
limsup
```




Como podemos observar, el intervalo obtenido utilizando la distribución normal es (`r liminf`,`r limsup`). Esto implica que en un 95% de los casos el verdadero valor de la emdia de la población se encontrará en este intervalo.


Finalmente, podemos añadir que los dos invertalos obtenidos para cada métodos son prácticamente el mismo.


</ul> 
<br> 





(e) **De una estimación de la varianza poblacional de "Distance". Llámela de $\tilde{\sigma}^2$.**

<ul>
Para dar una estimación de la varianza poblacional, podemos calcular la varianza de los datos de la muestra:


```{r}
sigma_tilde=sd(datos$Distance)**2
sigma_tilde
```

</ul> 
<br> 

(f) **Estime el error estándar de $\tilde{\sigma}^2$ usando el Bootstrap con $B = 100000$ muestras de boostrap.**

<ul>

Igual que en el apartado anterior, construimos la función que nos calculará el error estandar de la varianza para el método Bootstrap:


```{r}

err.est.varianza=function(x){
  sd(x)**2
}

err.est.varianza.fn=function(data, index){
  with(data[index,],err.est.varianza(Distance)) 
}

boot.out=boot(datos,err.est.varianza.fn,R=100000)
boot.out
```


Como podemos apreciar, el error estándar es muy grande: `r sd(boot.out$t)`, en consecuencia podemos decir que la estimación `r boot.out$t0` para la varianza de la poblabión del apartado anterior no es muy fiable.

</ul> 
<br> 

(g) **Estime el percentil 25% poblacional de "Distance". Llámelo de $\tilde{\mu}_{0.25}$ .**

<ul>

Para estimar el 25% poblacional de la variable Distance podemos calcular el primer quartil de nuestra muestra:

```{r}
quartil1=  as.numeric(quantile(datos$Distance,prob=0.25))
quartil1
```

</ul> 
<br> 

(h) **Estime el error estándar de $\tilde{\mu}_{0.25}$ usando el Bootstrap con $B = 100000$ muestras de boostrap. Interprete los resultados.**

<ul>

Igual que en el apartado anterior, construimos la función que nos calculará el primer quartil para el método Bootstrap:


```{r}
err.est.quantile=function(x){
 as.numeric(quantile(x,prob=0.25))
}

err.est.quantile.fn=function(data, index){
  with(data[index,],err.est.quantile(Distance)) 
}

boot.out=boot(datos,err.est.quantile.fn,R=100000)
boot.out
```

 Podemos observar que hemos obtenido la misma estimación del error estándar de $\tilde{\mu}$, como era de esperar (`r boot.out$t0`) . Por otro lado, el bias (`r -boot.out$t0+mean(boot.out$t)`) es pequeño y esto es bueno porque cuando más pequeño es,  más pequeño será la desviación estándar. Finalmente, podemos ver que hemos obtenido que una desviación estándar muy pequeña (`r sd(boot.out$t) `), por lo que podemos decir que la estimación del primer quartil del apartado anterior en la variable Distance es fiable.

</ul> 
<br> 

(i) **A partir de la estimación de Bootstrap del apartado (h), calcule un Intervalo de Confianza del 95% para el percentil 25% poblacional de "Distance". Utilice el método del percentil.**

<ul>
 Al igual que hemos realizado en el apartado d), para calcular el intervalo de confianza con el método del percentil cogeremos las 100000 estimaciones que se han considerado en la función boot del apartado anterior, las ordenaremos y nos quedaremos con el 95% central de las estimaciones:


```{r}
estimaciones=sort(boot.out$t,decreasing = FALSE)
lim_inf=round((length(estimaciones)+1)*(5/(2*100)))
lim_sup=round((length(estimaciones)+1)*(1-5/(2*100)))
intervalo=range(estimaciones[lim_inf:lim_sup])
intervalo
```

En consecuencia el intervalo obtenido es (`r intervalo[1]`,`r intervalo[2]`). Esto implica que en un 95% de los casos el verdadero valor del primer quartil de la población se encontrará en este intervalo.


</ul> 
<br> 

