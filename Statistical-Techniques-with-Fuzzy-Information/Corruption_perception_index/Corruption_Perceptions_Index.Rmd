---
title: "Perception Index Corruption"
subtitle: "Statistical Techniques with Fuzzy Information"
author: "Juan José Martín Miralles"
output:
  html_document:
    number_sections: false
    highlight: tango
    toc: yes
    df_print: paged
editor_options: 
  chunk_output_type: inline
---



<style type="text/css">

  body {
    background-color: #f6f7fd; 
  }
  
  a:link {
    color: #0174DF;
  }
  
  code.r {
    font-size: 14px;
  } 
  
  div pre {
    background-color:#E0ECF8;
  }
  pre {
    font-size: 14px 
  }
 
  p {
    text-align: justify;
  }
 
    
  h1, h2, h3, h4, h5, h6 {
    color: #737aaa;
  }

  th {  
    background-color:#737aaa;
    color: #FAFAFA;
    padding:5px;
  }
  
  td {
    font-size: 11.5pt;
  } 
  
  tr:nth-child(even){
    background: white;
  }
  
  tr:nth-child(odd){ 
    background-color: #EFF8FB;
  }
</style>

***     

<br/>    


```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.width=12, fig.height=8, fig.align="center", echo=TRUE, warning=FALSE, message=FALSE)
```

```{r}
library(FuzzyNumbers)
library(ggplot2)
library(gridExtra)
library(reshape2)
library(rworldmap)
```


### Análisis exploratorio de los datos

```{r}
data = read.csv('Corruption Perceptions Index - Dataset.csv', sep = ';')
data$african_union = as.logical(data$african_union)
data$arab_states = as.logical(data$arab_states)
data$BRICS = as.logical(data$BRICS)
data$EU = as.logical(data$EU)
data$G20 = as.logical(data$G20)
data$OECD = as.logical(data$OECD)

head(data)
```

<br>

```{r}
summary(data)
```

<br>

```{r}
str(data)
```

<br>

```{r}
cols = c('country', 
         'CPI_score_2012',
         'CPI_score_2013',
         'CPI_score_2014', 
         'CPI_score_2015', 
         'CPI_score_2016',
         'CPI_score_2017')
data_cpi = data[cols]
colnames(data_cpi) = c('country', '2012', '2013', '2014', '2015', '2016', '2017')

data_cpi_top_20 = head(data_cpi[sort(data_cpi$`2017`, decreasing = TRUE, index.return=TRUE)$ix, ], 20)
data_cpi_top_20_melt = melt(data_cpi_top_20, id.vars='country')
         
ggplot(data_cpi_top_20_melt, aes(x=variable, y=value, color=country)) + 
  geom_point() +
  geom_line(aes(group=country)) +
  scale_color_discrete(name="Countries",
                       breaks=data_cpi_top_20$country)
```

<br>

```{r}
data_cpi_top_20 = head(data_cpi[sort(data_cpi$`2017`, decreasing = FALSE, index.return=TRUE)$ix, ], 20)
data_cpi_top_20_melt = melt(data_cpi_top_20, id.vars='country')
         
ggplot(data_cpi_top_20_melt, aes(x=variable, y=value, color=country)) + 
  geom_point() +
  geom_line(aes(group=country)) +
  scale_color_discrete(name="Countries",
                       breaks=data_cpi_top_20$country)
```

<br>

```{r}
CPI_score_cols = c('CPI_score_2012',
                   'CPI_score_2013',
                   'CPI_score_2014', 
                   'CPI_score_2015', 
                   'CPI_score_2016',
                   'CPI_score_2017')
number_sources_cols = c('number_sources_2012',
                        'number_sources_2013',
                        'number_sources_2014', 
                        'number_sources_2015', 
                        'number_sources_2016',
                        'number_sources_2017')
cols = c(CPI_score_cols, number_sources_cols)

ame = sapply(data[data$region == 'AME', cols], mean)
we_eu = sapply(data[data$region == 'WE/EU', cols], mean)
ap = sapply(data[data$region == 'AP', cols], mean)
eca = sapply(data[data$region == 'ECA', cols], mean)
mena = sapply(data[data$region == 'MENA', cols], mean)
ssa = sapply(data[data$region == 'SSA', cols], mean)

regions = rbind(ame, we_eu, ap, eca, mena, ssa)
rownames(regions) = c('AME', 'WE/EU', 'AP', 'ECA', 'MENA', 'SSA')

cpi_score_df = regions[, CPI_score_cols]
colnames(cpi_score_df) = c('2012', '2013', '2014', '2015', '2016', '2017')
cpi_score_df_melt = melt(cpi_score_df, id.vars=rownames)

number_sources_df = regions[, number_sources_cols]
colnames(number_sources_df) = c('2012', '2013', '2014', '2015', '2016', '2017')
number_sources_df_melt = melt(number_sources_df, id.vars=rownames)
         
g1 = ggplot(cpi_score_df_melt, aes(x=Var1, y=value, fill=as.factor(Var2))) + 
  geom_bar(aes(group=Var2), stat = "identity", position = "dodge") +
  xlab("Regions") + ylab("Mean CPI") +
  ggtitle("Mean CPI by region and year") +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title=element_blank())
         
g2 = ggplot(number_sources_df_melt, aes(x=Var1, y=value, fill=as.factor(Var2))) + 
  geom_bar(aes(group=Var2), stat = "identity", position = "dodge") +
  xlab("Regions") + ylab("Mean number of sources") +
  ggtitle("Mean number of sources by region and year") +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title=element_blank())

grid.arrange(g1, g2, nrow = 1)
```

<br>

```{r}
african_union = sapply(data[data$african_union == TRUE, cols], mean)
arab_states = sapply(data[data$arab_states == TRUE, cols], mean)
BRICS = sapply(data[data$BRICS == TRUE, cols], mean)
EU = sapply(data[data$EU == TRUE, cols], mean)
G20 = sapply(data[data$G20 == TRUE, cols], mean)
OECD = sapply(data[data$OECD == TRUE, cols], mean)

economic_groups = rbind(african_union, arab_states, BRICS, EU, G20, OECD)
rownames(economic_groups) = c('African Union', 'Arab States', 'BRICS', 'EU', 'G20', 'OECD')

cpi_score_df = economic_groups[, CPI_score_cols]
colnames(cpi_score_df) = c('2012', '2013', '2014', '2015', '2016', '2017')
cpi_score_df_melt = melt(cpi_score_df, id.vars=rownames)

number_sources_df = economic_groups[, number_sources_cols]
colnames(number_sources_df) = c('2012', '2013', '2014', '2015', '2016', '2017')
number_sources_df_melt = melt(number_sources_df, id.vars=rownames)
         
g1 = ggplot(cpi_score_df_melt, aes(x=Var1, y=value, fill=as.factor(Var2))) + 
  geom_bar(aes(group=Var2), stat = "identity", position = "dodge") +
  xlab("Economic groups") + ylab("Mean CPI") +
  ggtitle("Mean CPI by economic group and year") +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title=element_blank())
         
g2 = ggplot(number_sources_df_melt, aes(x=Var1, y=value, fill=as.factor(Var2))) + 
  geom_bar(aes(group=Var2), stat = "identity", position = "dodge") +
  xlab("Economic groups") + ylab("Mean number of sources") +
  ggtitle("Mean number of sources by economic group and year") +
  theme(plot.title = element_text(hjust = 0.5),
        legend.title=element_blank())

grid.arrange(g1, g2, nrow = 1)
```

<br>

### Fuzzificación básica

```{r}
aux1 = data$lower_CI_2017
aux2 = data$CPI_score_2017 - data$standard_error_2017
aux3 = data$CPI_score_2017 + data$standard_error_2017
aux4 = data$upper_CI_2017

colors = rainbow(dim(data)[1])
fuzzyNumbers = c()
for(i in 1:nrow(data)) {
  fuzzy = PiecewiseLinearFuzzyNumber(aux1[i], aux2[i], aux3[i], aux4[i])
  fuzzyNumbers = c(fuzzyNumbers, fuzzy)
  
  add = TRUE
  if (i == 1) {
    add = FALSE
  }
  
  plot(fuzzy, add = add, col = colors[i], xlim = c(0, 100))
}
```

<br>

### Fuzzificación

```{r}
aux1 = data$lower_CI_2017 - (2 * (data$upper_CI_2017 - data$lower_CI_2017) * (1 - (data$number_sources_2017 / 13)))
aux2 = data$lower_CI_2017
aux3 = data$upper_CI_2017
aux4 = data$upper_CI_2017 + (2 * (data$upper_CI_2017 - data$lower_CI_2017) * (data$number_sources_2017 / 13))

colors = rainbow(dim(data)[1])
fuzzy_CPI = c()
for(i in 1:nrow(data)) {
  print(data$country[i])
  print(i)
  fuzzy = PiecewiseLinearFuzzyNumber(aux1[i], aux2[i], aux3[i], aux4[i])
  fuzzy_CPI = c(fuzzy_CPI, fuzzy)
  
  add = TRUE
  if (i == 1) {
    add = FALSE
  }
  
  plot(fuzzy, add = add, col = colors[i], xlim = c(-35, 130))
}
```

<br>

### Mediana borrosa

```{r}
fuzzy_quantile = function(fuzzy_number_list, deltas, p) {
  # Calculamos los alpha-cuts de todos los números borrosos
  alphacut_list = c()
  for(d in 1:length(deltas)) {
    alphacut = c()
    for(i in 1:length(fuzzy_number_list)) {
      alphacut = c(alphacut, alphacut(fuzzy_number_list[[i]], deltas[d]))
    }
    alphacut_list[[d]] = sort(alphacut)
  }
  
  freq_dist_L = matrix(rep(0, len = length(deltas) * length(fuzzy_number_list) * 2), 
                       nrow = length(deltas))
  freq_dist_U = matrix(rep(0, len = length(deltas) * length(fuzzy_number_list) * 2), 
                       nrow = length(deltas))
  
  # Iterate over alpha-cuts
  for (i in 1:(length(fuzzy_number_list) * 2)) { 
    # Iterate over the fuzzy numbers
    for (fuzzy_num in 1:length(fuzzy_number_list)) { 
      alphacut = alphacut(fuzzy_number_list[[fuzzy_num]], deltas)
      
      # Iterate over deltas
      for (d in 1:length(deltas)) { 
        # Intersec
        if(alphacut[d, 'L'] <= alphacut_list[[d]][i]) { 
          freq_dist_U[d, i] = freq_dist_U[d, i] + 1
        }
        
        # Subset
        if(alphacut[d, 'U'] <= alphacut_list[[d]][i]) { 
          freq_dist_L[d, i] = freq_dist_L[d, i] + 1
        }
      }
    }
  }
  
  freq_dist_L = freq_dist_L / length(fuzzy_number_list)
  freq_dist_U = freq_dist_U / length(fuzzy_number_list)
  
  m = matrix(rep(0, len = 2 * length(deltas)), nrow = length(deltas))
  fuzzy_quantile = data.frame(m, row.names = deltas)
  colnames(fuzzy_quantile) = c('L', 'U')
  
  # Upper
  for(r in 1:nrow(freq_dist_L)) {
    for(c in 1:ncol(freq_dist_L)) {
      if(freq_dist_L[r, c] >= p) {
        fuzzy_quantile[r, 'U'] = alphacut_list[[r]][c]
        break
      }
    }
  }
  
  # Lower
  for(r in 1:nrow(freq_dist_U)) {
    for(c in 1:ncol(freq_dist_U)) {
      if(freq_dist_U[r, c] >= p) {
        fuzzy_quantile[r, 'L'] = alphacut_list[[r]][c]
        break
      }
    }
  }
  
  return(fuzzy_quantile)
}
```

```{r}
delta = 0.5
p = 0.5

median_fuzzy_CPI = fuzzy_quantile(fuzzy_CPI, delta, p)
median_fuzzy_CPI
```

```{r}
CPI_score_cols = c('CPI_score_2017')

ame = median(data[data$region == 'AME', 'CPI_score_2017'])
we_eu = median(data[data$region == 'WE/EU', 'CPI_score_2017'])
ap = median(data[data$region == 'AP', 'CPI_score_2017'])
eca = median(data[data$region == 'ECA', 'CPI_score_2017'])
mena = median(data[data$region == 'MENA', 'CPI_score_2017'])
ssa = median(data[data$region == 'SSA', 'CPI_score_2017'])

regions = rbind(ame, we_eu, ap, eca, mena, ssa)
rownames(regions) = c('AME', 'WE/EU', 'AP', 'ECA', 'MENA', 'SSA')
regions
```


```{r}
tt = as.integer(rownames(data[data$region == 'SSA', ]))

delta = 0.5
p = 0.5

median_fuzzy_CPI = fuzzy_quantile(fuzzy_CPI[tt], delta, p)
median_fuzzy_CPI
```


<br>

### Reducción de las variables existentes

```{r}
data_sources = c('world_bank_CPIA', 
                 'world_economic_forum_EOS', 
                 'global_insight_country_risk_ratings',
                 'bertelsmann_foundation_transformation_index',
                 'african_development_bank_CPIA',
                 'IMD_world_competitiveness_yearbook',
                 'bertelsmann_foundation_sustainable_governance_index',
                 'world_justice_project_rule_of_law_index',
                 'PRS_international_country_risk_guide',
                 'varieties_of_democracy_project',
                 'economist_intelligence_unit_country_ratings',
                 'freedom_house_nations_in_transit_ratings',
                 'PERC_asia_risk_guide')

zero_counter = apply(data[data_sources], 2, function(x) length(which(x == 0))/length(x))
data_sources_selected = colnames(data[data_sources])[zero_counter <= 0.5]
data_sources_selected
```

<br>

```{r}
basic_columns = c('country',
                  'ISO3',
                  'region',
                  'african_union',
                  'arab_states',
                  'BRICS',
                  'EU',
                  'G20',
                  'OECD',
                  'CPI_score_2017',
                  'standard_error_2017',
                  'lower_CI_2017',
                  'upper_CI_2017',
                  'number_sources_2017')

data_sources_df = data[c(basic_columns, data_sources_selected)]
is.na(data_sources_df[data_sources_selected]) = data_sources_df[data_sources_selected] == 0
data_sources_df['new_CPI'] = round(rowMeans(data_sources_df[data_sources_selected], na.rm=TRUE))

data_sources_df['n_na'] = apply(data_sources_df[data_sources_selected], 1, function(x) sum(is.na(x)))
```


```{r}
basic_columns = c('country',
                  'ISO3',
                  'region',
                  'african_union',
                  'arab_states',
                  'BRICS',
                  'EU',
                  'G20',
                  'OECD',
                  'CPI_score_2017',
                  'standard_error_2017',
                  'lower_CI_2017',
                  'upper_CI_2017',
                  'number_sources_2017')

data_sources_df = data[c(basic_columns, data_sources)]
is.na(data_sources_df[data_sources]) = data_sources_df[data_sources] == 0
data_sources_df['new_CPI'] = rowMeans(data_sources_df[data_sources], na.rm=TRUE)

data_sources_df['n_na'] = 13 - apply(data_sources_df[data_sources_selected], 1, function(x) sum(is.na(x)))
```

```{r}
# View(data_sources_df[c('country', 'CPI_score_2017', 'new_CPI', 'n_na')])
```




### Map
```{r}
n = joinCountryData2Map(data, joinCode="ISO3", nameJoinColumn="ISO3")
mapParams = mapCountryData(n, 
                           nameColumnToPlot="CPI_score_2017", 
                           mapTitle="Crisp Corruption Perceptions Index 2017",
                           missingCountryCol="snow2",
                           colourPalette=c('darkred', 'red', 'yellow'),
                           addLegend=FALSE,
                           numCats=10,
                           catMethod=seq(from = 0, to = 100, by = 10))
do.call(addMapLegend,
        c(mapParams,
          legendLabels="all",
          legendWidth=0.5,
          legendIntervals="data",
          legendMar = 5))
```


